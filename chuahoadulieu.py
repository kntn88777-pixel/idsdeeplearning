# üöÄ TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU IDS + C√ÇN B·∫∞NG TR√äN GOOGLE COLAB

# 1. C√†i th∆∞ vi·ªán n·∫øu c·∫ßn
!pip install -q imbalanced-learn

# 2. Import th∆∞ vi·ªán
import pandas as pd
import numpy as np
import gc
import os
import matplotlib.pyplot as plt
import pickle
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from collections import Counter
from datetime import datetime
import seaborn as sns
from imblearn.over_sampling import RandomOverSampler

# 3. Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# 4. ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a c√°c file CSV
csv_folder = '/content/drive/MyDrive/ColabNotebooks/nienluancoso1/DATA/CSE-IDS2018'
print(f"[1] ƒê·ªçc d·ªØ li·ªáu t·ª´ th∆∞ m·ª•c: {csv_folder}")

# 5. ƒê·ªçc & g·ªôp c√°c file CSV
df_list = []
for filename in os.listdir(csv_folder):
    if filename.endswith('.csv'):
        filepath = os.path.join(csv_folder, filename)
        print(f"    ‚Üí ƒêang ƒë·ªçc: {filename}")
        try:
            df = pd.read_csv(filepath, low_memory=False)
            df.drop(columns=['Flow ID', 'Timestamp'], inplace=True, errors='ignore')
            df.replace([np.inf, -np.inf], np.nan, inplace=True)
            df.dropna(inplace=True)
            if 'Label' in df.columns:
                df_list.append(df)
        except Exception as e:
            print(f"    ‚ùå L·ªói ƒë·ªçc {filename}: {e}")

if not df_list:
    raise ValueError("‚ùå Kh√¥ng c√≥ file CSV h·ª£p l·ªá!")

df = pd.concat(df_list, ignore_index=True)
print(f"[2] T·ªïng s·ªë d√≤ng sau khi g·ªôp: {df.shape[0]}, s·ªë c·ªôt: {df.shape[1]}")

gc.collect()

# 6. T√°ch ƒë·∫∑c tr∆∞ng v√† nh√£n
if 'Label' not in df.columns:
    raise ValueError("‚ùå Kh√¥ng t√¨m th·∫•y c·ªôt 'Label'!")

X = df.drop(columns=['Label'])
y = df['Label']

# 7. M√£ ho√° c√°c c·ªôt d·∫°ng chu·ªói
print("[3] M√£ ho√° c√°c c·ªôt d·∫°ng chu·ªói...")
for col in X.select_dtypes(include=['object']).columns:
    X[col] = LabelEncoder().fit_transform(X[col].astype(str))
    print(f"    ‚Üí {col} ƒë√£ m√£ ho√°.")

# 8. M√£ ho√° nh√£n
print("[4] M√£ ho√° nh√£n Label...")
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

# 9. Hi·ªÉn th·ªã ph√¢n ph·ªëi tr∆∞·ªõc c√¢n b·∫±ng
print("[üìä] Ph√¢n ph·ªëi nh√£n tr∆∞·ªõc khi c√¢n b·∫±ng:")
class_counts = pd.Series(y).value_counts()
class_labels = label_encoder.inverse_transform(class_counts.index)

plt.figure(figsize=(10, 5))
sns.barplot(x=class_labels, y=class_counts.values, palette='viridis')
plt.title("S·ªë l∆∞·ª£ng m·∫´u theo l·ªõp tr∆∞·ªõc khi c√¢n b·∫±ng", fontsize=14)
plt.xlabel("L·ªõp (Label)")
plt.ylabel("S·ªë l∆∞·ª£ng m·∫´u")
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# 10. C√¢n b·∫±ng d·ªØ li·ªáu b·∫±ng RandomOverSampler
print("[‚öñÔ∏è] C√¢n b·∫±ng d·ªØ li·ªáu b·∫±ng RandomOverSampler...")
ros = RandomOverSampler(random_state=42)
X_resampled, y_resampled = ros.fit_resample(X, y)

# In ph√¢n ph·ªëi sau khi c√¢n b·∫±ng
print("[üìä] Ph√¢n ph·ªëi nh√£n sau khi c√¢n b·∫±ng:")
balanced_counts = Counter(y_resampled)
for idx, count in balanced_counts.items():
    label = label_encoder.inverse_transform([idx])[0]
    print(f"    {label}: {count} m·∫´u")

# 11. Chu·∫©n ho√° ƒë·∫∑c tr∆∞ng
print("[5] Chu·∫©n ho√° ƒë·∫∑c tr∆∞ng b·∫±ng StandardScaler...")
X_scaled = StandardScaler().fit_transform(X_resampled)

# 12. Chia train/test
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled
)
print(f"[6] Train: {X_train.shape}, Test: {X_test.shape}")

# 13. L∆∞u ra CSV v√† NPY
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
output_dir = '/content/drive/MyDrive/ColabNotebooks/nienluancoso1/output'
os.makedirs(output_dir, exist_ok=True)

# Ghi train
train_df = pd.DataFrame(X_train, columns=X.columns)
train_df['Label'] = y_train
train_csv = os.path.join(output_dir, f"train_data_{timestamp}.csv")
train_df.to_csv(train_csv, index=False)
print(f"‚úÖ ƒê√£ ghi t·∫≠p hu·∫•n luy·ªán: {train_csv}")

# Ghi test
test_df = pd.DataFrame(X_test, columns=X.columns)
test_df['Label'] = y_test
test_csv = os.path.join(output_dir, f"test_data_{timestamp}.csv")
test_df.to_csv(test_csv, index=False)
print(f"‚úÖ ƒê√£ ghi t·∫≠p ki·ªÉm tra: {test_csv}")

# Ghi file numpy
np.save(os.path.join(output_dir, "X_train.npy"), X_train)
np.save(os.path.join(output_dir, "X_test.npy"), X_test)
np.save(os.path.join(output_dir, "y_train.npy"), y_train)
np.save(os.path.join(output_dir, "y_test.npy"), y_test)
print("‚úÖ ƒê√£ ghi file X_train.npy, X_test.npy, y_train.npy, y_test.npy")
